{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\n"
     ]
    }
   ],
   "source": [
    "%env LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":/home/nkspartan/miniconda3/envs/tf-gpu/lib/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ[\"LD_LIBRARY_PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "\n",
    "from keras import Sequential, models, Input\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 14:58:21.553282: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 14:58:21.571295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 14:58:21.571505: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:58:21.571556: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:58:21.571596: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:58:21.571635: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:58:21.571675: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:58:21.571713: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:58:21.571751: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:58:21.571789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:58:21.571795: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "#print(device_lib.list_local_devices())\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the csv dataset to get the values for stage and discharge of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SensorTime</th>\n",
       "      <th>CaptureTime</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Agency</th>\n",
       "      <th>SiteNumber</th>\n",
       "      <th>TimeZone</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Discharge</th>\n",
       "      <th>CalcTimestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>WeirPt2X</th>\n",
       "      <th>WeirPt2Y</th>\n",
       "      <th>WwRawLineMin</th>\n",
       "      <th>WwRawLineMax</th>\n",
       "      <th>WwRawLineMean</th>\n",
       "      <th>WwRawLineSigma</th>\n",
       "      <th>WwCurveLineMin</th>\n",
       "      <th>WwCurveLineMax</th>\n",
       "      <th>WwCurveLineMean</th>\n",
       "      <th>WwCurveLineSigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012-06-09 13:15:00</td>\n",
       "      <td>2012-06-09T13:09:07</td>\n",
       "      <td>StateLineWeir_20120609_Farrell_001.jpg</td>\n",
       "      <td>USGS</td>\n",
       "      <td>6674500</td>\n",
       "      <td>MDT</td>\n",
       "      <td>2.99</td>\n",
       "      <td>916.0</td>\n",
       "      <td>2020-03-11T16:58:28</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-06-09 13:15:00</td>\n",
       "      <td>2012-06-09T13:10:29</td>\n",
       "      <td>StateLineWeir_20120609_Farrell_002.jpg</td>\n",
       "      <td>USGS</td>\n",
       "      <td>6674500</td>\n",
       "      <td>MDT</td>\n",
       "      <td>2.99</td>\n",
       "      <td>916.0</td>\n",
       "      <td>2020-03-11T16:58:33</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-06-09 13:45:00</td>\n",
       "      <td>2012-06-09T13:44:01</td>\n",
       "      <td>StateLineWeir_20120609_Farrell_003.jpg</td>\n",
       "      <td>USGS</td>\n",
       "      <td>6674500</td>\n",
       "      <td>MDT</td>\n",
       "      <td>2.96</td>\n",
       "      <td>873.0</td>\n",
       "      <td>2020-03-11T16:58:40</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2012-06-09 14:45:00</td>\n",
       "      <td>2012-06-09T14:44:30</td>\n",
       "      <td>StateLineWeir_20120609_Farrell_004.jpg</td>\n",
       "      <td>USGS</td>\n",
       "      <td>6674500</td>\n",
       "      <td>MDT</td>\n",
       "      <td>2.94</td>\n",
       "      <td>846.0</td>\n",
       "      <td>2020-03-11T16:58:47</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-06-09 15:45:00</td>\n",
       "      <td>2012-06-09T15:44:59</td>\n",
       "      <td>StateLineWeir_20120609_Farrell_005.jpg</td>\n",
       "      <td>USGS</td>\n",
       "      <td>6674500</td>\n",
       "      <td>MDT</td>\n",
       "      <td>2.94</td>\n",
       "      <td>846.0</td>\n",
       "      <td>2020-03-11T16:58:55</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           SensorTime          CaptureTime  \\\n",
       "0           0  2012-06-09 13:15:00  2012-06-09T13:09:07   \n",
       "1           1  2012-06-09 13:15:00  2012-06-09T13:10:29   \n",
       "2           2  2012-06-09 13:45:00  2012-06-09T13:44:01   \n",
       "3           3  2012-06-09 14:45:00  2012-06-09T14:44:30   \n",
       "4           4  2012-06-09 15:45:00  2012-06-09T15:44:59   \n",
       "\n",
       "                                 Filename Agency  SiteNumber TimeZone  Stage  \\\n",
       "0  StateLineWeir_20120609_Farrell_001.jpg   USGS     6674500      MDT   2.99   \n",
       "1  StateLineWeir_20120609_Farrell_002.jpg   USGS     6674500      MDT   2.99   \n",
       "2  StateLineWeir_20120609_Farrell_003.jpg   USGS     6674500      MDT   2.96   \n",
       "3  StateLineWeir_20120609_Farrell_004.jpg   USGS     6674500      MDT   2.94   \n",
       "4  StateLineWeir_20120609_Farrell_005.jpg   USGS     6674500      MDT   2.94   \n",
       "\n",
       "   Discharge        CalcTimestamp  ...  WeirPt2X  WeirPt2Y  WwRawLineMin  \\\n",
       "0      916.0  2020-03-11T16:58:28  ...        -1        -1           0.0   \n",
       "1      916.0  2020-03-11T16:58:33  ...        -1        -1           0.0   \n",
       "2      873.0  2020-03-11T16:58:40  ...        -1        -1           0.0   \n",
       "3      846.0  2020-03-11T16:58:47  ...        -1        -1           0.0   \n",
       "4      846.0  2020-03-11T16:58:55  ...        -1        -1           0.0   \n",
       "\n",
       "   WwRawLineMax  WwRawLineMean  WwRawLineSigma  WwCurveLineMin  \\\n",
       "0           0.0            0.0             0.0             0.0   \n",
       "1           0.0            0.0             0.0             0.0   \n",
       "2           0.0            0.0             0.0             0.0   \n",
       "3           0.0            0.0             0.0             0.0   \n",
       "4           0.0            0.0             0.0             0.0   \n",
       "\n",
       "   WwCurveLineMax  WwCurveLineMean  WwCurveLineSigma  \n",
       "0             0.0              0.0               0.0  \n",
       "1             0.0              0.0               0.0  \n",
       "2             0.0              0.0               0.0  \n",
       "3             0.0              0.0               0.0  \n",
       "4             0.0              0.0               0.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/2012_2019_PlatteRiverWeir_features_merged_all.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "\n",
    "def make_dataset(path, batch_size, df):\n",
    "\n",
    "  def parse_image(filename):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    #image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    return image\n",
    "\n",
    "  def configure_for_performance(ds):\n",
    "    ds = ds.shuffle(buffer_size=100)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "  filenames = glob(path + '/*')\n",
    "  random.shuffle(filenames)\n",
    "\n",
    "  stage_values = [df[df.Filename == file.split('/')[-1]].Stage.values for file in filenames]\n",
    "  discharge_values = [df[df.Filename == file.split('/')[-1]].Discharge.values for file in filenames]\n",
    "\n",
    "  stage_discharge_values = [[np.squeeze(s), np.squeeze(d)] for s, d in zip(stage_values, discharge_values)]\n",
    "\n",
    "  filenames_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "  images_ds = filenames_ds.map(parse_image, num_parallel_calls=5)\n",
    "  stage_discharge_ds = tf.data.Dataset.from_tensor_slices(stage_discharge_values)\n",
    "  ds = tf.data.Dataset.zip((images_ds, stage_discharge_ds))\n",
    "  ds = configure_for_performance(ds)\n",
    "\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 14:58:33.977300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 14:58:33.977474: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "path = \"../dataset/images_tmp\"\n",
    "\n",
    "ds = make_dataset(path, 32, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 512, 512, 3)\n",
      "(32, 2)\n"
     ]
    }
   ],
   "source": [
    "input_shape = 0\n",
    "output_shape = 0\n",
    "\n",
    "for image, stage_discharge in ds.take(1):\n",
    "    print(image.numpy().shape)\n",
    "    print(stage_discharge.numpy().shape)\n",
    "\n",
    "    input_shape = image.numpy().shape[1:]\n",
    "    output_shape = stage_discharge.numpy().shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions_tf(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=100):\n",
    "    assert (train_split + test_split + val_split) == 1.0\n",
    "    \n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(ds, 16, val_split=0.2, test_split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, output_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='sigmoid'))\n",
    "    model.add(Dense(32, activation='sigmoid'))\n",
    "    model.add(Dense(output_shape, activation='linear')) # linear regression output layer\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(input_shape, output_shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 510, 510, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 255, 255, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 253, 253, 32)      18464     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 84, 84, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 82, 82, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 41, 41, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 39, 39, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 19, 19, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 11552)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                369696    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 409,570\n",
      "Trainable params: 409,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(loss_func, optimizer, metrics=[\"accuracy\"]):\n",
    "    model.compile(loss=loss_func, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = Adam(learning_rate=1e-3, decay=1e-3 / 200)\n",
    "\n",
    "compile_model('mean_squared_error', adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(training_values, validation_values=None, batch_size=32, epochs=10, steps=32):\n",
    "    return model.fit(training_values, validation_data=validation_values, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 41s 4s/step - loss: 1385847.5000 - accuracy: 0.9833\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 40s 4s/step - loss: 1385226.1250 - accuracy: 0.9833\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 40s 4s/step - loss: 1384736.3750 - accuracy: 0.9833\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 40s 4s/step - loss: 1384260.6250 - accuracy: 0.9833\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 40s 4s/step - loss: 1383821.6250 - accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 0 because we already have batch size in tf dataset\n",
    "history = fit_model(ds, None, batch_size=32, epochs=5, steps=np.ceil(300/32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "79f576286c1276b480d6696ed40f6607e18214e4a2875a618cb5be817ff26007"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
